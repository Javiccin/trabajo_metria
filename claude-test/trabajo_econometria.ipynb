{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajo Practico de Econometria\n",
    "**Maestrias en Economia y Econometria**\n",
    "\n",
    "Seed: 1910"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Seed para replicabilidad\n",
    "SEED = 1910\n",
    "\n",
    "# Parametros del modelo\n",
    "N_SIM = 5000\n",
    "BETA0_TRUE = -3.0\n",
    "BETA1_TRUE = 0.8\n",
    "OMEGA_DIAG = np.array([4.0, 9.0, 16.0, 25.0, 36.0])  # varianzas por grupo\n",
    "N_GROUPS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Parte 1: Propiedades de muestra finita de FGLS (MCGE)\n",
    "\n",
    "**Modelo:** $y_i = \\beta_0 + \\beta_1 x_i + u_i$, con $\\beta_0 = -3$, $\\beta_1 = 0.8$\n",
    "\n",
    "$u \\sim N(0, \\Omega \\otimes I_N)$, $\\Omega = \\text{diag}(4, 9, 16, 25, 36)$, $x \\sim U[1, 50]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(n_total, beta0, beta1, rng):\n",
    "    \"\"\"\n",
    "    Genera una muestra de tamano n_total = 5*N del modelo (1).\n",
    "    Cada grupo j (j=0,...,4) tiene N = n_total/5 observaciones con varianza Omega[j,j].\n",
    "    \"\"\"\n",
    "    N = n_total // N_GROUPS\n",
    "    x = rng.uniform(1, 50, size=n_total)\n",
    "\n",
    "    # Errores con heterocedasticidad grupal\n",
    "    u = np.zeros(n_total)\n",
    "    for j in range(N_GROUPS):\n",
    "        sigma_j = np.sqrt(OMEGA_DIAG[j])\n",
    "        u[j * N:(j + 1) * N] = rng.normal(0, sigma_j, size=N)\n",
    "\n",
    "    y = beta0 + beta1 * x + u\n",
    "    return y, x\n",
    "\n",
    "\n",
    "def ols(y, X):\n",
    "    \"\"\"Estimacion por MCC (OLS).\"\"\"\n",
    "    return np.linalg.solve(X.T @ X, X.T @ y)\n",
    "\n",
    "\n",
    "def fgls(y, X, n_total):\n",
    "    \"\"\"\n",
    "    Estimacion por FGLS (MCGE).\n",
    "    1. Estimar OLS y obtener residuos\n",
    "    2. Estimar varianza por grupo con residuos al cuadrado (correccion por g.d.l.)\n",
    "    3. GLS con Omega_hat estimada\n",
    "    Retorna coeficientes y errores estandar.\n",
    "    \"\"\"\n",
    "    N = n_total // N_GROUPS\n",
    "    k = X.shape[1]  # numero de regresores (2: constante + x)\n",
    "\n",
    "    # Paso 1: OLS\n",
    "    beta_ols = ols(y, X)\n",
    "    residuals = y - X @ beta_ols\n",
    "\n",
    "    # Paso 2: Estimar varianzas por grupo con correccion por grados de libertad\n",
    "    # Multiplicamos por n/(n-k) para corregir el sesgo de los residuos OLS\n",
    "    df_correction = n_total / (n_total - k)\n",
    "    sigma2_hat = np.zeros(n_total)\n",
    "    for j in range(N_GROUPS):\n",
    "        idx = slice(j * N, (j + 1) * N)\n",
    "        sigma2_j = np.mean(residuals[idx] ** 2) * df_correction\n",
    "        sigma2_hat[idx] = sigma2_j\n",
    "\n",
    "    # Paso 3: GLS -> beta_hat = (X'Omega_inv X)^{-1} X'Omega_inv y\n",
    "    Omega_inv = np.diag(1.0 / sigma2_hat)\n",
    "    XtOiX = X.T @ Omega_inv @ X\n",
    "    XtOiX_inv = np.linalg.inv(XtOiX)\n",
    "    beta_fgls = XtOiX_inv @ (X.T @ Omega_inv @ y)\n",
    "\n",
    "    # Varianza FGLS: (X'Omega_inv X)^{-1}\n",
    "    se_beta = np.sqrt(np.diag(XtOiX_inv))\n",
    "\n",
    "    return beta_fgls, se_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gls(y, X, Omega):\n",
    "    \"\"\"\n",
    "    Estimacion por GLS (MCG) con Omega conocida.\n",
    "    beta_gls = (X' Omega_inv X)^{-1} X' Omega_inv y\n",
    "    Retorna coeficientes y errores estandar.\n",
    "    \"\"\"\n",
    "    Omega_inv = np.linalg.inv(Omega)\n",
    "    XtOiX = X.T @ Omega_inv @ X\n",
    "    XtOiX_inv = np.linalg.inv(XtOiX)\n",
    "    beta_gls = XtOiX_inv @ (X.T @ Omega_inv @ y)\n",
    "\n",
    "    # Varianza GLS: (X' Omega_inv X)^{-1}\n",
    "    se_beta = np.sqrt(np.diag(XtOiX_inv))\n",
    "\n",
    "    return beta_gls, se_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation_1a(n_total):\n",
    "    \"\"\"\n",
    "    Simulacion punto 1a para un tamano de muestra dado.\n",
    "    - Tamano del test: datos generados con beta1=0.8 (H0 verdadera)\n",
    "    - Poder del test: datos generados con beta1=0 y beta1=0.4 (H0 falsa)\n",
    "    Usa valores criticos de la normal estandar (distribucion asintotica de FGLS).\n",
    "    \"\"\"\n",
    "    beta0_est = np.zeros(N_SIM)\n",
    "    beta1_est = np.zeros(N_SIM)\n",
    "    t_size = np.zeros(N_SIM)\n",
    "    t_power_0 = np.zeros(N_SIM)\n",
    "    t_power_04 = np.zeros(N_SIM)\n",
    "\n",
    "    rng = np.random.RandomState(SEED)\n",
    "\n",
    "    for sim in range(N_SIM):\n",
    "        # Datos bajo H0 verdadera: beta1 = 0.8\n",
    "        y, x = generate_data(n_total, BETA0_TRUE, BETA1_TRUE, rng)\n",
    "        X = np.column_stack([np.ones(n_total), x])\n",
    "        beta_hat, se_hat = fgls(y, X, n_total)\n",
    "        beta0_est[sim] = beta_hat[0]\n",
    "        beta1_est[sim] = beta_hat[1]\n",
    "        t_size[sim] = (beta_hat[1] - 0.8) / se_hat[1]\n",
    "\n",
    "        # Datos bajo beta1 = 0 (poder)\n",
    "        y0, x0 = generate_data(n_total, BETA0_TRUE, 0.0, rng)\n",
    "        X0 = np.column_stack([np.ones(n_total), x0])\n",
    "        b0, se0 = fgls(y0, X0, n_total)\n",
    "        t_power_0[sim] = (b0[1] - 0.8) / se0[1]\n",
    "\n",
    "        # Datos bajo beta1 = 0.4 (poder)\n",
    "        y04, x04 = generate_data(n_total, BETA0_TRUE, 0.4, rng)\n",
    "        X04 = np.column_stack([np.ones(n_total), x04])\n",
    "        b04, se04 = fgls(y04, X04, n_total)\n",
    "        t_power_04[sim] = (b04[1] - 0.8) / se04[1]\n",
    "\n",
    "    # Valores criticos de la normal estandar (distribucion asintotica)\n",
    "    cv_1 = stats.norm.ppf(1 - 0.01 / 2)\n",
    "    cv_5 = stats.norm.ppf(1 - 0.05 / 2)\n",
    "\n",
    "    results = {\n",
    "        'n_total': n_total,\n",
    "        'beta0_mean': np.mean(beta0_est),\n",
    "        'beta0_median': np.median(beta0_est),\n",
    "        'beta0_std': np.std(beta0_est),\n",
    "        'beta1_mean': np.mean(beta1_est),\n",
    "        'beta1_median': np.median(beta1_est),\n",
    "        'beta1_std': np.std(beta1_est),\n",
    "        'size_1': np.mean(np.abs(t_size) > cv_1) * 100,\n",
    "        'size_5': np.mean(np.abs(t_size) > cv_5) * 100,\n",
    "        'power_b1_0_at_1': np.mean(np.abs(t_power_0) > cv_1) * 100,\n",
    "        'power_b1_0_at_5': np.mean(np.abs(t_power_0) > cv_5) * 100,\n",
    "        'power_b1_04_at_1': np.mean(np.abs(t_power_04) > cv_1) * 100,\n",
    "        'power_b1_04_at_5': np.mean(np.abs(t_power_04) > cv_5) * 100,\n",
    "    }\n",
    "    return results\n",
    "\n",
    "\n",
    "def print_results(res):\n",
    "    \"\"\"Imprime resultados de la simulacion.\"\"\"\n",
    "    print(\"=\" * 65)\n",
    "    print(f\"  FGLS - Tamano de muestra: 5N = {res['n_total']}\")\n",
    "    print(\"=\" * 65)\n",
    "\n",
    "    print()\n",
    "    print(f\"--- Estimaciones de beta0 (verdadero = -3.0) ---\")\n",
    "    print(f\"  Media:    {res['beta0_mean']:.6f}\")\n",
    "    print(f\"  Mediana:  {res['beta0_median']:.6f}\")\n",
    "    print(f\"  Desvio:   {res['beta0_std']:.6f}\")\n",
    "\n",
    "    print()\n",
    "    print(f\"--- Estimaciones de beta1 (verdadero = 0.8) ---\")\n",
    "    print(f\"  Media:    {res['beta1_mean']:.6f}\")\n",
    "    print(f\"  Mediana:  {res['beta1_median']:.6f}\")\n",
    "    print(f\"  Desvio:   {res['beta1_std']:.6f}\")\n",
    "\n",
    "    print()\n",
    "    print(f\"--- Tamano del test (H0: beta1 = 0.8) ---\")\n",
    "    print(f\"  Al 1%:  {res['size_1']:.2f}%  (nominal: 1%)\")\n",
    "    print(f\"  Al 5%:  {res['size_5']:.2f}%  (nominal: 5%)\")\n",
    "\n",
    "    print()\n",
    "    print(f\"--- Poder del test (H0: beta1 = 0.8) ---\")\n",
    "    print(f\"  beta1 = 0:    al 1%: {res['power_b1_0_at_1']:.2f}%  |  al 5%: {res['power_b1_0_at_5']:.2f}%\")\n",
    "    print(f\"  beta1 = 0.4:  al 1%: {res['power_b1_04_at_1']:.2f}%  |  al 5%: {res['power_b1_04_at_5']:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 1a;2-6: 5N = n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "  FGLS - Tamano de muestra: 5N = 5\n",
      "=================================================================\n",
      "\n",
      "--- Estimaciones de beta0 (verdadero = -3.0) ---\n",
      "  Media:    -2.917793\n",
      "  Mediana:  -2.934760\n",
      "  Desvio:   5.597167\n",
      "\n",
      "--- Estimaciones de beta1 (verdadero = 0.8) ---\n",
      "  Media:    0.794782\n",
      "  Mediana:  0.795753\n",
      "  Desvio:   0.192855\n",
      "\n",
      "--- Tamano del test (H0: beta1 = 0.8) ---\n",
      "  Al 1%:  28.64%  (nominal: 1%)\n",
      "  Al 5%:  38.30%  (nominal: 5%)\n",
      "\n",
      "--- Poder del test (H0: beta1 = 0.8) ---\n",
      "  beta1 = 0:    al 1%: 96.96%  |  al 5%: 98.34%\n",
      "  beta1 = 0.4:  al 1%: 80.82%  |  al 5%: 87.68%\n",
      "=================================================================\n",
      "  FGLS - Tamano de muestra: 5N = 10\n",
      "=================================================================\n",
      "\n",
      "--- Estimaciones de beta0 (verdadero = -3.0) ---\n",
      "  Media:    -2.966155\n",
      "  Mediana:  -3.001572\n",
      "  Desvio:   3.034392\n",
      "\n",
      "--- Estimaciones de beta1 (verdadero = 0.8) ---\n",
      "  Media:    0.799587\n",
      "  Mediana:  0.799594\n",
      "  Desvio:   0.105066\n",
      "\n",
      "--- Tamano del test (H0: beta1 = 0.8) ---\n",
      "  Al 1%:  16.28%  (nominal: 1%)\n",
      "  Al 5%:  25.90%  (nominal: 5%)\n",
      "\n",
      "--- Poder del test (H0: beta1 = 0.8) ---\n",
      "  beta1 = 0:    al 1%: 99.96%  |  al 5%: 100.00%\n",
      "  beta1 = 0.4:  al 1%: 95.66%  |  al 5%: 97.90%\n",
      "=================================================================\n",
      "  FGLS - Tamano de muestra: 5N = 30\n",
      "=================================================================\n",
      "\n",
      "--- Estimaciones de beta0 (verdadero = -3.0) ---\n",
      "  Media:    -3.019120\n",
      "  Mediana:  -3.006129\n",
      "  Desvio:   1.393574\n",
      "\n",
      "--- Estimaciones de beta1 (verdadero = 0.8) ---\n",
      "  Media:    0.800590\n",
      "  Mediana:  0.799987\n",
      "  Desvio:   0.048002\n",
      "\n",
      "--- Tamano del test (H0: beta1 = 0.8) ---\n",
      "  Al 1%:  4.38%  (nominal: 1%)\n",
      "  Al 5%:  11.58%  (nominal: 5%)\n",
      "\n",
      "--- Poder del test (H0: beta1 = 0.8) ---\n",
      "  beta1 = 0:    al 1%: 100.00%  |  al 5%: 100.00%\n",
      "  beta1 = 0.4:  al 1%: 100.00%  |  al 5%: 100.00%\n",
      "=================================================================\n",
      "  FGLS - Tamano de muestra: 5N = 100\n",
      "=================================================================\n",
      "\n",
      "--- Estimaciones de beta0 (verdadero = -3.0) ---\n",
      "  Media:    -3.011505\n",
      "  Mediana:  -3.010009\n",
      "  Desvio:   0.700019\n",
      "\n",
      "--- Estimaciones de beta1 (verdadero = 0.8) ---\n",
      "  Media:    0.800362\n",
      "  Mediana:  0.800191\n",
      "  Desvio:   0.023856\n",
      "\n",
      "--- Tamano del test (H0: beta1 = 0.8) ---\n",
      "  Al 1%:  1.78%  (nominal: 1%)\n",
      "  Al 5%:  7.06%  (nominal: 5%)\n",
      "\n",
      "--- Poder del test (H0: beta1 = 0.8) ---\n",
      "  beta1 = 0:    al 1%: 100.00%  |  al 5%: 100.00%\n",
      "  beta1 = 0.4:  al 1%: 100.00%  |  al 5%: 100.00%\n",
      "=================================================================\n",
      "  FGLS - Tamano de muestra: 5N = 200\n",
      "=================================================================\n",
      "\n",
      "--- Estimaciones de beta0 (verdadero = -3.0) ---\n",
      "  Media:    -3.012201\n",
      "  Mediana:  -3.018735\n",
      "  Desvio:   0.481081\n",
      "\n",
      "--- Estimaciones de beta1 (verdadero = 0.8) ---\n",
      "  Media:    0.800345\n",
      "  Mediana:  0.800144\n",
      "  Desvio:   0.016464\n",
      "\n",
      "--- Tamano del test (H0: beta1 = 0.8) ---\n",
      "  Al 1%:  1.40%  (nominal: 1%)\n",
      "  Al 5%:  6.12%  (nominal: 5%)\n",
      "\n",
      "--- Poder del test (H0: beta1 = 0.8) ---\n",
      "  beta1 = 0:    al 1%: 100.00%  |  al 5%: 100.00%\n",
      "  beta1 = 0.4:  al 1%: 100.00%  |  al 5%: 100.00%\n",
      "=================================================================\n",
      "  FGLS - Tamano de muestra: 5N = 500\n",
      "=================================================================\n",
      "\n",
      "--- Estimaciones de beta0 (verdadero = -3.0) ---\n",
      "  Media:    -3.003061\n",
      "  Mediana:  -3.004237\n",
      "  Desvio:   0.294945\n",
      "\n",
      "--- Estimaciones de beta1 (verdadero = 0.8) ---\n",
      "  Media:    0.799976\n",
      "  Mediana:  0.799934\n",
      "  Desvio:   0.010099\n",
      "\n",
      "--- Tamano del test (H0: beta1 = 0.8) ---\n",
      "  Al 1%:  1.04%  (nominal: 1%)\n",
      "  Al 5%:  5.20%  (nominal: 5%)\n",
      "\n",
      "--- Poder del test (H0: beta1 = 0.8) ---\n",
      "  beta1 = 0:    al 1%: 100.00%  |  al 5%: 100.00%\n",
      "  beta1 = 0.4:  al 1%: 100.00%  |  al 5%: 100.00%\n"
     ]
    }
   ],
   "source": [
    "for n in [5,10,30,100,200,500]:\n",
    "    res_5 = run_simulation_1a(n_total=n)\n",
    "    print_results(res_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Punto 1b: Descomposicion de Cholesky\n",
    "\n",
    "Se busca $P$ tal que $\\Omega = P \\cdot P'$. Luego se transforma el modelo:\n",
    "\n",
    "$$P^{-1} y = P^{-1} X \\beta + P^{-1} u$$\n",
    "\n",
    "donde $P^{-1} u$ tiene covarianza $P^{-1} \\Omega (P^{-1})' = P^{-1} P P' (P^{-1})' = I$.\n",
    "\n",
    "Al estimar por OLS el modelo transformado ($y^* = X^* \\beta + u^*$) se obtiene el estimador GLS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz Omega (5x5 para N=1):\n",
      "[[ 4.  0.  0.  0.  0.]\n",
      " [ 0.  9.  0.  0.  0.]\n",
      " [ 0.  0. 16.  0.  0.]\n",
      " [ 0.  0.  0. 25.  0.]\n",
      " [ 0.  0.  0.  0. 36.]]\n",
      "\n",
      "Matriz P (Cholesky, Omega = P * P'):\n",
      "[[2. 0. 0. 0. 0.]\n",
      " [0. 3. 0. 0. 0.]\n",
      " [0. 0. 4. 0. 0.]\n",
      " [0. 0. 0. 5. 0.]\n",
      " [0. 0. 0. 0. 6.]]\n",
      "\n",
      "Verificacion P * P' = Omega: True\n",
      "\n",
      "=================================================================\n",
      "  Comparacion GLS (Cholesky+OLS) vs FGLS  |  5N = 5\n",
      "=================================================================\n",
      "\n",
      "--- beta0 (verdadero = -3.0) ---\n",
      "                         GLS (Cholesky)             FGLS\n",
      "  Media                       -3.030895        -3.045046\n",
      "  Mediana                     -3.066153        -3.024660\n",
      "  Desvio                       4.850936         5.631405\n",
      "\n",
      "--- beta1 (verdadero = 0.8) ---\n",
      "                         GLS (Cholesky)             FGLS\n",
      "  Media                        0.799237         0.799445\n",
      "  Mediana                      0.800106         0.798205\n",
      "  Desvio                       0.166821         0.192225\n"
     ]
    }
   ],
   "source": [
    "def run_simulation_1b(n_total=5):\n",
    "    \"\"\"\n",
    "    Punto 1b: GLS via Cholesky + OLS sobre modelo transformado.\n",
    "    Usa Omega verdadera (conocida), no estimada.\n",
    "    Compara con FGLS del punto 1a.\n",
    "    \"\"\"\n",
    "    N = n_total // N_GROUPS\n",
    "\n",
    "    # Construir Omega completa (5N x 5N): diagonal con varianzas por grupo\n",
    "    omega_full = np.diag(np.repeat(OMEGA_DIAG, N))\n",
    "\n",
    "    # Descomposicion de Cholesky: Omega = P * P'\n",
    "    P = np.linalg.cholesky(omega_full)\n",
    "    P_inv = np.linalg.inv(P)\n",
    "\n",
    "    print(\"Matriz Omega (5x5 para N=1):\")\n",
    "    print(omega_full)\n",
    "    print(\"\\nMatriz P (Cholesky, Omega = P * P'):\")\n",
    "    print(P)\n",
    "    print(\"\\nVerificacion P * P' = Omega:\", np.allclose(P @ P.T, omega_full))\n",
    "\n",
    "    # Simulacion\n",
    "    beta0_gls = np.zeros(N_SIM)\n",
    "    beta1_gls = np.zeros(N_SIM)\n",
    "    beta0_fgls = np.zeros(N_SIM)\n",
    "    beta1_fgls = np.zeros(N_SIM)\n",
    "\n",
    "    rng = np.random.RandomState(SEED)\n",
    "\n",
    "    for sim in range(N_SIM):\n",
    "        y, x = generate_data(n_total, BETA0_TRUE, BETA1_TRUE, rng)\n",
    "        X = np.column_stack([np.ones(n_total), x])\n",
    "\n",
    "        # --- GLS via Cholesky: transformar y estimar OLS ---\n",
    "        y_star = P_inv @ y        # y* = P^{-1} y\n",
    "        X_star = P_inv @ X        # X* = P^{-1} X\n",
    "        beta_cholesky = ols(y_star, X_star)\n",
    "        beta0_gls[sim] = beta_cholesky[0]\n",
    "        beta1_gls[sim] = beta_cholesky[1]\n",
    "\n",
    "        # --- FGLS (del punto 1a) para comparar ---\n",
    "        beta_fgls_hat, _ = fgls(y, X, n_total)\n",
    "        beta0_fgls[sim] = beta_fgls_hat[0]\n",
    "        beta1_fgls[sim] = beta_fgls_hat[1]\n",
    "\n",
    "    # Reportar comparacion\n",
    "    print(\"\\n\" + \"=\" * 65)\n",
    "    print(f\"  Comparacion GLS (Cholesky+OLS) vs FGLS  |  5N = {n_total}\")\n",
    "    print(\"=\" * 65)\n",
    "\n",
    "    print(\"\\n--- beta0 (verdadero = -3.0) ---\")\n",
    "    print(f\"  {'':20s} {'GLS (Cholesky)':>16s} {'FGLS':>16s}\")\n",
    "    print(f\"  {'Media':20s} {np.mean(beta0_gls):16.6f} {np.mean(beta0_fgls):16.6f}\")\n",
    "    print(f\"  {'Mediana':20s} {np.median(beta0_gls):16.6f} {np.median(beta0_fgls):16.6f}\")\n",
    "    print(f\"  {'Desvio':20s} {np.std(beta0_gls):16.6f} {np.std(beta0_fgls):16.6f}\")\n",
    "\n",
    "    print(\"\\n--- beta1 (verdadero = 0.8) ---\")\n",
    "    print(f\"  {'':20s} {'GLS (Cholesky)':>16s} {'FGLS':>16s}\")\n",
    "    print(f\"  {'Media':20s} {np.mean(beta1_gls):16.6f} {np.mean(beta1_fgls):16.6f}\")\n",
    "    print(f\"  {'Mediana':20s} {np.median(beta1_gls):16.6f} {np.median(beta1_fgls):16.6f}\")\n",
    "    print(f\"  {'Desvio':20s} {np.std(beta1_gls):16.6f} {np.std(beta1_fgls):16.6f}\")\n",
    "\n",
    "run_simulation_1b(n_total=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2: Propiedades de muestra finita del test de White\n",
    "\n",
    "**Modelo:** $y_i = \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\sqrt{\\nu_i} u_i$, con $\\beta_0 = \\beta_1 = \\beta_2 = 1$\n",
    "\n",
    "**Diseno 0:** $u_i \\sim N(0,1)$, $\\nu_i = 1$ (homocedasticidad)\n",
    "\n",
    "**Diseno 1:** $u_i \\sim N(0,1)$, $\\nu_i = e^{0.25 x_{1i} + 0.25 x_{2i}}$ (heterocedasticidad)\n",
    "\n",
    "**Diseno 2:** $u_i \\sim t_5$, $\\nu_i = e^{0.25 x_{1i} + 0.25 x_{2i}}$ (no-normalidad + heterocedasticidad)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 2.1 Test de Heterocedasticidad de White"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Generacion de x1 y x2 para la Parte 2\n",
    "# ============================================================================\n",
    "\n",
    "def generate_x_part2(n, rng):\n",
    "    \"\"\"\n",
    "    Genera x1 y x2 para el modelo (2).\n",
    "    Base (n=20): x1 = 18 puntos equiespaciados entre -1 y 1 + extremos -1.1 y 1.1\n",
    "                 x2 = cuantiles de N(0,1) aleatorios\n",
    "    Para n > 20: se repiten las 20 observaciones base las veces necesarias.\n",
    "    \"\"\"\n",
    "    # Base de 20 observaciones\n",
    "    x1_interior = np.linspace(-1, 1, 18)\n",
    "    x1_base = np.concatenate([[-1.1], x1_interior, [1.1]])  # 20 puntos\n",
    "    x2_base = rng.normal(0, 1, size=20)\n",
    "\n",
    "    # Repetir para obtener n observaciones\n",
    "    reps = n // 20\n",
    "    x1 = np.tile(x1_base, reps)\n",
    "    x2 = np.tile(x2_base, reps)\n",
    "\n",
    "    return x1, x2\n",
    "\n",
    "\n",
    "def generate_y_part2(x1, x2, design, rng):\n",
    "    \"\"\"\n",
    "    Genera y del modelo (2) segun el diseno.\n",
    "    y_i = 1 + 1*x1_i + 1*x2_i + sqrt(nu_i)*u_i\n",
    "    Diseno 0: u~N(0,1), nu=1\n",
    "    Diseno 1: u~N(0,1), nu=exp(0.25*x1 + 0.25*x2)\n",
    "    Diseno 2: u~t5,     nu=exp(0.25*x1 + 0.25*x2)\n",
    "    \"\"\"\n",
    "    n = len(x1)\n",
    "\n",
    "    if design == 0:\n",
    "        u = rng.normal(0, 1, size=n)\n",
    "        nu = np.ones(n)\n",
    "    elif design == 1:\n",
    "        u = rng.normal(0, 1, size=n)\n",
    "        nu = np.exp(0.25 * x1 + 0.25 * x2)\n",
    "    elif design == 2:\n",
    "        u = rng.standard_t(df=5, size=n)\n",
    "        nu = np.exp(0.25 * x1 + 0.25 * x2)\n",
    "\n",
    "    y = 1 + 1 * x1 + 1 * x2 + np.sqrt(nu) * u\n",
    "    return y\n",
    "\n",
    "\n",
    "def white_test(y, X):\n",
    "    \"\"\"\n",
    "    Test de White para heterocedasticidad.\n",
    "    1. OLS del modelo original, obtener residuos\n",
    "    2. Regresion auxiliar: e^2 ~ 1 + x1 + x2 + x1^2 + x2^2 + x1*x2\n",
    "    3. Estadistico W = n * R^2 ~ chi2(q)\n",
    "    Retorna el p-valor del test.\n",
    "    \"\"\"\n",
    "    n = X.shape[0]\n",
    "\n",
    "    # Paso 1: OLS y residuos\n",
    "    beta_hat = ols(y, X)\n",
    "    e = y - X @ beta_hat\n",
    "    e2 = e ** 2\n",
    "\n",
    "    # Paso 2: Regresion auxiliar\n",
    "    # X tiene columnas: [1, x1, x2]\n",
    "    x1 = X[:, 1]\n",
    "    x2 = X[:, 2]\n",
    "    Z = np.column_stack([\n",
    "        np.ones(n),   # constante\n",
    "        x1,           # x1\n",
    "        x2,           # x2\n",
    "        x1 ** 2,      # x1^2\n",
    "        x2 ** 2,      # x2^2\n",
    "        x1 * x2       # x1*x2\n",
    "    ])\n",
    "\n",
    "    # OLS de e^2 sobre Z\n",
    "    alpha_hat = ols(e2, Z)\n",
    "    e2_fitted = Z @ alpha_hat\n",
    "    ss_res = np.sum((e2 - e2_fitted) ** 2)\n",
    "    ss_tot = np.sum((e2 - np.mean(e2)) ** 2)\n",
    "    R2 = 1 - ss_res / ss_tot\n",
    "\n",
    "    # Paso 3: Estadistico W = n * R^2\n",
    "    q = Z.shape[1] - 1  # grados de libertad (regresores sin constante = 5)\n",
    "    W = n * R2\n",
    "    p_value = 1 - stats.chi2.cdf(W, df=q)\n",
    "\n",
    "    return p_value\n",
    "\n",
    "\n",
    "def run_white_test_simulation(n, designs, rng_seed=SEED):\n",
    "    \"\"\"\n",
    "    Ejecuta 5000 simulaciones del test de White para los disenos dados.\n",
    "    Reporta tamano (diseno 0) y poder (disenos 1 y 2).\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "\n",
    "    for design in designs:\n",
    "        rng = np.random.RandomState(rng_seed)\n",
    "        # Generar x1, x2 una sola vez (son fijos across simulations)\n",
    "        rng_x = np.random.RandomState(rng_seed)\n",
    "        x1, x2 = generate_x_part2(n, rng_x)\n",
    "        X = np.column_stack([np.ones(n), x1, x2])\n",
    "\n",
    "        p_values = np.zeros(N_SIM)\n",
    "        for sim in range(N_SIM):\n",
    "            y = generate_y_part2(x1, x2, design, rng)\n",
    "            p_values[sim] = white_test(y, X)\n",
    "\n",
    "        # Tasa de rechazo a distintos niveles\n",
    "        reject_1 = np.mean(p_values < 0.01) * 100\n",
    "        reject_5 = np.mean(p_values < 0.05) * 100\n",
    "        reject_10 = np.mean(p_values < 0.10) * 100\n",
    "\n",
    "        results[design] = {\n",
    "            'reject_1': reject_1,\n",
    "            'reject_5': reject_5,\n",
    "            'reject_10': reject_10,\n",
    "        }\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def print_white_results(results, n):\n",
    "    \"\"\"Imprime resultados del test de White.\"\"\"\n",
    "    print(\"=\" * 65)\n",
    "    print(f\"  Test de White - n = {n}\")\n",
    "    print(\"=\" * 65)\n",
    "\n",
    "    if 0 in results:\n",
    "        r = results[0]\n",
    "        print(f\"\\n  Diseno 0 (homocedasticidad) - TAMANO del test:\")\n",
    "        print(f\"    Al  1%: {r['reject_1']:.2f}%  (nominal:  1%)\")\n",
    "        print(f\"    Al  5%: {r['reject_5']:.2f}%  (nominal:  5%)\")\n",
    "        print(f\"    Al 10%: {r['reject_10']:.2f}%  (nominal: 10%)\")\n",
    "\n",
    "    if 1 in results:\n",
    "        r = results[1]\n",
    "        print(f\"\\n  Diseno 1 (normal + heterocedasticidad) - PODER del test:\")\n",
    "        print(f\"    Al  1%: {r['reject_1']:.2f}%\")\n",
    "        print(f\"    Al  5%: {r['reject_5']:.2f}%\")\n",
    "        print(f\"    Al 10%: {r['reject_10']:.2f}%\")\n",
    "\n",
    "    if 2 in results:\n",
    "        r = results[2]\n",
    "        print(f\"\\n  Diseno 2 (t5 + heterocedasticidad) - PODER del test:\")\n",
    "        print(f\"    Al  1%: {r['reject_1']:.2f}%\")\n",
    "        print(f\"    Al  5%: {r['reject_5']:.2f}%\")\n",
    "        print(f\"    Al 10%: {r['reject_10']:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1a) Diseno 0 (tamano) + 2.1b) Disenos 1 y 2 (poder) para todos los n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "  Test de White - n = 20\n",
      "=================================================================\n",
      "\n",
      "  Diseno 0 (homocedasticidad) - TAMANO del test:\n",
      "    Al  1%: 0.48%  (nominal:  1%)\n",
      "    Al  5%: 4.60%  (nominal:  5%)\n",
      "    Al 10%: 9.04%  (nominal: 10%)\n",
      "\n",
      "  Diseno 1 (normal + heterocedasticidad) - PODER del test:\n",
      "    Al  1%: 0.60%\n",
      "    Al  5%: 6.00%\n",
      "    Al 10%: 11.38%\n",
      "\n",
      "  Diseno 2 (t5 + heterocedasticidad) - PODER del test:\n",
      "    Al  1%: 0.76%\n",
      "    Al  5%: 6.92%\n",
      "    Al 10%: 12.26%\n",
      "\n",
      "=================================================================\n",
      "  Test de White - n = 60\n",
      "=================================================================\n",
      "\n",
      "  Diseno 0 (homocedasticidad) - TAMANO del test:\n",
      "    Al  1%: 0.90%  (nominal:  1%)\n",
      "    Al  5%: 4.86%  (nominal:  5%)\n",
      "    Al 10%: 9.94%  (nominal: 10%)\n",
      "\n",
      "  Diseno 1 (normal + heterocedasticidad) - PODER del test:\n",
      "    Al  1%: 5.14%\n",
      "    Al  5%: 14.66%\n",
      "    Al 10%: 23.86%\n",
      "\n",
      "  Diseno 2 (t5 + heterocedasticidad) - PODER del test:\n",
      "    Al  1%: 3.44%\n",
      "    Al  5%: 11.20%\n",
      "    Al 10%: 18.06%\n",
      "\n",
      "=================================================================\n",
      "  Test de White - n = 100\n",
      "=================================================================\n",
      "\n",
      "  Diseno 0 (homocedasticidad) - TAMANO del test:\n",
      "    Al  1%: 1.08%  (nominal:  1%)\n",
      "    Al  5%: 4.70%  (nominal:  5%)\n",
      "    Al 10%: 9.78%  (nominal: 10%)\n",
      "\n",
      "  Diseno 1 (normal + heterocedasticidad) - PODER del test:\n",
      "    Al  1%: 11.04%\n",
      "    Al  5%: 26.66%\n",
      "    Al 10%: 39.46%\n",
      "\n",
      "  Diseno 2 (t5 + heterocedasticidad) - PODER del test:\n",
      "    Al  1%: 5.06%\n",
      "    Al  5%: 15.10%\n",
      "    Al 10%: 22.88%\n",
      "\n",
      "=================================================================\n",
      "  Test de White - n = 200\n",
      "=================================================================\n",
      "\n",
      "  Diseno 0 (homocedasticidad) - TAMANO del test:\n",
      "    Al  1%: 0.96%  (nominal:  1%)\n",
      "    Al  5%: 4.88%  (nominal:  5%)\n",
      "    Al 10%: 9.42%  (nominal: 10%)\n",
      "\n",
      "  Diseno 1 (normal + heterocedasticidad) - PODER del test:\n",
      "    Al  1%: 33.44%\n",
      "    Al  5%: 58.92%\n",
      "    Al 10%: 72.06%\n",
      "\n",
      "  Diseno 2 (t5 + heterocedasticidad) - PODER del test:\n",
      "    Al  1%: 11.24%\n",
      "    Al  5%: 26.82%\n",
      "    Al 10%: 38.78%\n",
      "\n",
      "=================================================================\n",
      "  Test de White - n = 400\n",
      "=================================================================\n",
      "\n",
      "  Diseno 0 (homocedasticidad) - TAMANO del test:\n",
      "    Al  1%: 1.02%  (nominal:  1%)\n",
      "    Al  5%: 5.34%  (nominal:  5%)\n",
      "    Al 10%: 9.52%  (nominal: 10%)\n",
      "\n",
      "  Diseno 1 (normal + heterocedasticidad) - PODER del test:\n",
      "    Al  1%: 79.92%\n",
      "    Al  5%: 93.86%\n",
      "    Al 10%: 97.26%\n",
      "\n",
      "  Diseno 2 (t5 + heterocedasticidad) - PODER del test:\n",
      "    Al  1%: 28.48%\n",
      "    Al  5%: 52.40%\n",
      "    Al 10%: 64.68%\n",
      "\n",
      "=================================================================\n",
      "  Test de White - n = 600\n",
      "=================================================================\n",
      "\n",
      "  Diseno 0 (homocedasticidad) - TAMANO del test:\n",
      "    Al  1%: 1.24%  (nominal:  1%)\n",
      "    Al  5%: 4.90%  (nominal:  5%)\n",
      "    Al 10%: 10.28%  (nominal: 10%)\n",
      "\n",
      "  Diseno 1 (normal + heterocedasticidad) - PODER del test:\n",
      "    Al  1%: 97.52%\n",
      "    Al  5%: 99.62%\n",
      "    Al 10%: 99.86%\n",
      "\n",
      "  Diseno 2 (t5 + heterocedasticidad) - PODER del test:\n",
      "    Al  1%: 47.88%\n",
      "    Al  5%: 71.14%\n",
      "    Al 10%: 80.78%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Correr test de White para todos los tamanos de muestra y los 3 disenos\n",
    "sample_sizes_p2 = [20, 60, 100, 200, 400, 600]\n",
    "\n",
    "for n in sample_sizes_p2:\n",
    "    res = run_white_test_simulation(n, designs=[0, 1, 2])\n",
    "    print_white_results(res, n)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Correccion de la matriz de varianzas y covarianzas (White)\n",
    "\n",
    "Sesgo relativo: $b_j = \\frac{1}{S}\\sum_{s=1}^{S} \\frac{\\widehat{Var}(\\hat\\beta_j)^{(s)} - Var(\\hat\\beta_j)}{Var(\\hat\\beta_j)}$\n",
    "\n",
    "Sesgo relativo total: $|b_0| + |b_1| + |b_2|$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "  Sesgo relativo de White (residuos OLS)\n",
      "======================================================================\n",
      "\n",
      "--- Diseno 1 ---\n",
      "      n          b0          b1          b2    |b0|+|b1|+|b2|\n",
      "     20     -0.1592     -0.2099     -0.2123            0.5813\n",
      "     60     -0.0511     -0.0677     -0.0644            0.1831\n",
      "    100     -0.0317     -0.0430     -0.0407            0.1154\n",
      "    200     -0.0160     -0.0204     -0.0204            0.0568\n",
      "    400     -0.0070     -0.0093     -0.0088            0.0251\n",
      "    600     -0.0048     -0.0055     -0.0067            0.0171\n",
      "\n",
      "--- Diseno 2 ---\n",
      "      n          b0          b1          b2    |b0|+|b1|+|b2|\n",
      "     20     -0.1546     -0.2071     -0.2226            0.5843\n",
      "     60     -0.0614     -0.0730     -0.0790            0.2133\n",
      "    100     -0.0364     -0.0443     -0.0466            0.1273\n",
      "    200     -0.0182     -0.0204     -0.0250            0.0636\n",
      "    400     -0.0094     -0.0093     -0.0140            0.0327\n",
      "    600     -0.0049     -0.0036     -0.0088            0.0173\n"
     ]
    }
   ],
   "source": [
    "def white_variance_simulation(n, design, use_true_errors=False, rng_seed=SEED):\n",
    "    \"\"\"\n",
    "    Parte 2.2: Sesgo relativo de la estimacion de White de la matriz de var-cov.\n",
    "    \n",
    "    Var_true = (X'X)^{-1} X' Omega_true X (X'X)^{-1}  (varianza verdadera de OLS)\n",
    "    Var_hat  = (X'X)^{-1} X' Omega_hat  X (X'X)^{-1}  (estimacion de White)\n",
    "    \n",
    "    Omega_hat = diag(e_hat^2) si use_true_errors=False (residuos)\n",
    "    Omega_hat = diag(epsilon^2) si use_true_errors=True (errores verdaderos)\n",
    "    \"\"\"\n",
    "    rng_x = np.random.RandomState(rng_seed)\n",
    "    x1, x2 = generate_x_part2(n, rng_x)\n",
    "    X = np.column_stack([np.ones(n), x1, x2])\n",
    "    \n",
    "    # Varianza de u segun diseno\n",
    "    if design == 1:\n",
    "        var_u = 1.0  # u ~ N(0,1)\n",
    "    elif design == 2:\n",
    "        var_u = 5.0 / 3.0  # u ~ t5, Var(t5) = 5/(5-2)\n",
    "    \n",
    "    # nu_i para heterocedasticidad\n",
    "    nu = np.exp(0.25 * x1 + 0.25 * x2)\n",
    "    \n",
    "    # Varianza verdadera de epsilon_i = sqrt(nu_i)*u_i es: nu_i * Var(u)\n",
    "    sigma2_true = nu * var_u\n",
    "    Omega_true = np.diag(sigma2_true)\n",
    "    \n",
    "    # Varianza verdadera de beta_hat OLS: (X'X)^{-1} X' Omega_true X (X'X)^{-1}\n",
    "    XtX_inv = np.linalg.inv(X.T @ X)\n",
    "    Var_true = XtX_inv @ X.T @ Omega_true @ X @ XtX_inv\n",
    "    var_true_diag = np.diag(Var_true)  # [Var(b0), Var(b1), Var(b2)]\n",
    "    \n",
    "    # Simulacion\n",
    "    rng = np.random.RandomState(rng_seed)\n",
    "    relative_bias = np.zeros((N_SIM, 3))  # para b0, b1, b2\n",
    "    \n",
    "    for sim in range(N_SIM):\n",
    "        # Generar errores\n",
    "        if design == 1:\n",
    "            u = rng.normal(0, 1, size=n)\n",
    "        elif design == 2:\n",
    "            u = rng.standard_t(df=5, size=n)\n",
    "        \n",
    "        epsilon = np.sqrt(nu) * u\n",
    "        y = 1 + 1 * x1 + 1 * x2 + epsilon\n",
    "        \n",
    "        # OLS\n",
    "        beta_hat = ols(y, X)\n",
    "        e_hat = y - X @ beta_hat\n",
    "        \n",
    "        # Estimacion de White\n",
    "        if use_true_errors:\n",
    "            Omega_hat = np.diag(epsilon ** 2)  # errores verdaderos\n",
    "        else:\n",
    "            Omega_hat = np.diag(e_hat ** 2)    # residuos OLS\n",
    "        \n",
    "        Var_hat = XtX_inv @ X.T @ Omega_hat @ X @ XtX_inv\n",
    "        var_hat_diag = np.diag(Var_hat)\n",
    "        \n",
    "        # Sesgo relativo para esta simulacion\n",
    "        relative_bias[sim, :] = (var_hat_diag - var_true_diag) / var_true_diag\n",
    "    \n",
    "    # Promediar sobre simulaciones\n",
    "    b = np.mean(relative_bias, axis=0)  # b0, b1, b2\n",
    "    total_bias = np.sum(np.abs(b))\n",
    "    \n",
    "    return b, total_bias\n",
    "\n",
    "\n",
    "def run_white_variance_all(use_true_errors=False):\n",
    "    \"\"\"Corre la simulacion 2.2 para todos los n y disenos.\"\"\"\n",
    "    sample_sizes = [20, 60, 100, 200, 400, 600]\n",
    "    label = \"errores verdaderos\" if use_true_errors else \"residuos OLS\"\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(f\"  Sesgo relativo de White ({label})\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    for design in [1, 2]:\n",
    "        print(f\"\\n--- Diseno {design} ---\")\n",
    "        print(f\"  {'n':>5s}  {'b0':>10s}  {'b1':>10s}  {'b2':>10s}  {'|b0|+|b1|+|b2|':>16s}\")\n",
    "        \n",
    "        for n in sample_sizes:\n",
    "            b, total = white_variance_simulation(n, design, use_true_errors)\n",
    "            print(f\"  {n:5d}  {b[0]:10.4f}  {b[1]:10.4f}  {b[2]:10.4f}  {total:16.4f}\")\n",
    "\n",
    "\n",
    "# a-f) Con residuos OLS (estimacion estandar de White)\n",
    "run_white_variance_all(use_true_errors=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2g) Repetir con errores verdaderos en vez de residuos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "  Sesgo relativo de White (errores verdaderos)\n",
      "======================================================================\n",
      "\n",
      "--- Diseno 1 ---\n",
      "      n          b0          b1          b2    |b0|+|b1|+|b2|\n",
      "     20      0.0018     -0.0008      0.0144            0.0169\n",
      "     60      0.0006      0.0011      0.0069            0.0086\n",
      "    100     -0.0006     -0.0015      0.0031            0.0052\n",
      "    200     -0.0003      0.0004      0.0014            0.0021\n",
      "    400      0.0008      0.0008      0.0019            0.0034\n",
      "    600      0.0004      0.0013      0.0005            0.0023\n",
      "\n",
      "--- Diseno 2 ---\n",
      "      n          b0          b1          b2    |b0|+|b1|+|b2|\n",
      "     20     -0.0018     -0.0109     -0.0158            0.0286\n",
      "     60     -0.0097     -0.0067     -0.0086            0.0250\n",
      "    100     -0.0050     -0.0039     -0.0036            0.0125\n",
      "    200     -0.0025     -0.0006     -0.0042            0.0073\n",
      "    400     -0.0017      0.0005     -0.0035            0.0057\n",
      "    600      0.0003      0.0030     -0.0019            0.0052\n"
     ]
    }
   ],
   "source": [
    "# g) Con errores verdaderos (epsilon^2 en vez de e_hat^2)\n",
    "run_white_variance_all(use_true_errors=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
